"""
AIæ™ºèƒ½ä½“ç»ˆç«¯æ§åˆ¶å·¥å…·Demo
æ¼”ç¤ºAI Agentå¦‚ä½•é€šè¿‡è‡ªç„¶è¯­è¨€æ§åˆ¶ç»ˆç«¯æ‰§è¡Œå‘½ä»¤

è¿è¡Œ: python3 terminal_agent_demo.py
"""

import subprocess
import json
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# ============================================
# é…ç½®åŒº
# ============================================
# é€šç”¨LLMé…ç½® - ç”¨äºæ„å›¾åˆ†æã€é—®ç­”ç­‰
LLM_CONFIG = {
    "model": "gpt-4.1-mini",
    "base_url": "https://sdwfger.edu.kg/v1",
    "api_key": "sk-lCVcio0vmI5U16K1ru9gdJ7ZsszU3lsKnUurlNjhROjWLwxU",
    "temperature": 0,
}

# ä»£ç ç”Ÿæˆä¸“ç”¨LLMé…ç½® - ç”¨äºç”Ÿæˆå‘½ä»¤å’Œä»£ç 
LLM_CONFIG2 = {
    "model": "claude-3-5-sonnet",  # ä½¿ç”¨Claudeä½œä¸ºä»£ç ç”Ÿæˆæ¨¡å‹
    "base_url": "https://sdwfger.edu.kg/v1",
    "api_key": "sk-lCVcio0vmI5U16K1ru9gdJ7ZsszU3lsKnUurlNjhROjWLwxU",
    "temperature": 0,
}


# ============================================
# æ•°æ®ç»“æ„å®šä¹‰
# ============================================
class AgentState(TypedDict):
    """æ™ºèƒ½ä½“çŠ¶æ€"""
    user_input: str
    intent: Literal["terminal_command", "multi_step_command", "question", "unknown"]
    command: str
    commands: list  # å¤šæ­¥éª¤å‘½ä»¤åˆ—è¡¨
    command_output: str
    command_outputs: list  # å¤šä¸ªå‘½ä»¤çš„è¾“å‡º
    response: str
    error: str
    needs_file_creation: bool  # æ˜¯å¦éœ€è¦åˆ›å»ºæ–‡ä»¶
    file_path: str  # è¦åˆ›å»ºçš„æ–‡ä»¶è·¯å¾„
    file_content: str  # æ–‡ä»¶å†…å®¹


# ============================================
# åˆå§‹åŒ– LLM
# ============================================
# é€šç”¨LLM - ç”¨äºæ„å›¾åˆ†æã€é—®ç­”ç­‰
llm = ChatOpenAI(
    model=LLM_CONFIG["model"],
    base_url=LLM_CONFIG["base_url"],
    api_key=LLM_CONFIG["api_key"],
    temperature=LLM_CONFIG["temperature"],
    default_headers={
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
)

# ä»£ç ç”Ÿæˆä¸“ç”¨LLM - ç”¨äºç”Ÿæˆå‘½ä»¤å’Œä»£ç 
llm_code = ChatOpenAI(
    model=LLM_CONFIG2["model"],
    base_url=LLM_CONFIG2["base_url"],
    api_key=LLM_CONFIG2["api_key"],
    temperature=LLM_CONFIG2["temperature"],
    default_headers={
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
)


# ============================================
# å·¥å…·å‡½æ•° - ç»ˆç«¯å‘½ä»¤æ‰§è¡Œ
# ============================================

def execute_terminal_command(command: str) -> dict:
    """
    å®‰å…¨åœ°æ‰§è¡Œç»ˆç«¯å‘½ä»¤
    è¿”å›: {"success": bool, "output": str, "error": str}
    """
    # å®‰å…¨æ£€æŸ¥ - ç¦æ­¢å±é™©å‘½ä»¤
    dangerous_commands = ["rm -rf", "sudo", "chmod", "format", "del /f"]
    for dangerous in dangerous_commands:
        if dangerous in command.lower():
            return {
                "success": False,
                "output": "",
                "error": f"æ‹’ç»æ‰§è¡Œå±é™©å‘½ä»¤: {command}"
            }

    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=10
        )
        return {
            "success": result.returncode == 0,
            "output": result.stdout,
            "error": result.stderr
        }
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "output": "",
            "error": "å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
        }
    except Exception as e:
        return {
            "success": False,
            "output": "",
            "error": f"æ‰§è¡Œå¤±è´¥: {str(e)}"
        }


# ============================================
# èŠ‚ç‚¹å‡½æ•°å®šä¹‰
# ============================================

def intent_analyzer(state: AgentState) -> dict:
    """
    åˆ†æç”¨æˆ·æ„å›¾: æ˜¯è¦æ‰§è¡Œç»ˆç«¯å‘½ä»¤è¿˜æ˜¯é—®é—®é¢˜
    """
    user_input = state["user_input"]

    prompt = f"""åˆ†æç”¨æˆ·æ„å›¾,åªè¿”å›ä¸€ä¸ªè¯: 'terminal_command', 'multi_step_command' æˆ– 'question'

ç”¨æˆ·è¾“å…¥: {user_input}

åˆ¤æ–­è§„åˆ™:
- å¦‚æœç”¨æˆ·æƒ³æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ã€æŸ¥çœ‹æ–‡ä»¶ã€è¿è¡Œç¨‹åº -> terminal_command
- å¦‚æœç”¨æˆ·éœ€è¦åˆ›å»ºæ–‡ä»¶å¹¶æ‰§è¡Œã€æˆ–è€…éœ€è¦å¤šä¸ªæ­¥éª¤å®Œæˆä»»åŠ¡ -> multi_step_command
- å¦‚æœç”¨æˆ·åœ¨é—®é—®é¢˜ã€å¯»æ±‚è§£é‡Šã€éœ€è¦å»ºè®® -> question

æ„å›¾:"""

    result = llm.invoke([HumanMessage(content=prompt)])
    intent = result.content.strip().lower()

    if intent not in ["terminal_command", "multi_step_command", "question"]:
        intent = "unknown"

    print(f"\n[æ„å›¾åˆ†æ] {user_input}")
    print(f"           æ„å›¾: {intent}")

    return {"intent": intent}


def command_generator(state: AgentState) -> dict:
    """
    å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»ˆç«¯å‘½ä»¤
    """
    user_input = state["user_input"]

    prompt = f"""å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¯·æ±‚è½¬æ¢ä¸ºç»ˆç«¯å‘½ä»¤ã€‚åªè¿”å›å‘½ä»¤æœ¬èº«,ä¸è¦è§£é‡Šã€‚

ç”¨æˆ·è¯·æ±‚: {user_input}

ç¤ºä¾‹:
- "åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶" -> ls -la
- "æŸ¥çœ‹Pythonç‰ˆæœ¬" -> python3 --version
- "æ˜¾ç¤ºå½“å‰è·¯å¾„" -> pwd
- "åˆ›å»ºä¸€ä¸ªåä¸ºtest.txtçš„æ–‡ä»¶" -> touch test.txt

ç»ˆç«¯å‘½ä»¤:"""

    result = llm_code.invoke([HumanMessage(content=prompt)])  # ä½¿ç”¨ä»£ç ç”ŸæˆLLM
    command = result.content.strip()

    print(f"[å‘½ä»¤ç”Ÿæˆ] {command}")

    return {"command": command}


def multi_step_planner(state: AgentState) -> dict:
    """
    å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤ï¼Œå¹¶è¯†åˆ«æ˜¯å¦éœ€è¦åˆ›å»ºæ–‡ä»¶ï¼ˆä½¿ç”¨ä»£ç ç”ŸæˆLLMï¼‰
    """
    user_input = state["user_input"]

    prompt = f"""åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œè¿”å›JSONæ ¼å¼çš„æ‰§è¡Œè®¡åˆ’ã€‚

ç”¨æˆ·è¯·æ±‚: {user_input}

ä½ éœ€è¦è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«:
{{
  "needs_file_creation": true/false,  # æ˜¯å¦éœ€è¦åˆ›å»ºæ–‡ä»¶
  "file_path": "æ–‡ä»¶è·¯å¾„",  # å¦‚æœéœ€è¦åˆ›å»ºæ–‡ä»¶
  "file_content": "æ–‡ä»¶å†…å®¹",  # å¦‚æœéœ€è¦åˆ›å»ºæ–‡ä»¶
  "commands": ["å‘½ä»¤1", "å‘½ä»¤2"]  # è¦æ‰§è¡Œçš„ç»ˆç«¯å‘½ä»¤åˆ—è¡¨
}}

ç¤ºä¾‹1:
è¾“å…¥: "åˆ›å»ºä¸€ä¸ªPythonæ–‡ä»¶hello.pyï¼Œå†…å®¹æ˜¯print('Hello World')ï¼Œç„¶åæ‰§è¡Œå®ƒ"
è¾“å‡º:
{{
  "needs_file_creation": true,
  "file_path": "hello.py",
  "file_content": "print('Hello World')",
  "commands": ["python3 hello.py"]
}}

ç¤ºä¾‹2:
è¾“å…¥: "æŸ¥çœ‹å½“å‰ç›®å½•ç„¶åæ˜¾ç¤ºPythonç‰ˆæœ¬"
è¾“å‡º:
{{
  "needs_file_creation": false,
  "file_path": "",
  "file_content": "",
  "commands": ["pwd", "python3 --version"]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š:"""

    result = llm_code.invoke([HumanMessage(content=prompt)])  # ä½¿ç”¨ä»£ç ç”ŸæˆLLM
    plan_text = result.content.strip()
    
    # æå–JSONå†…å®¹
    if "```json" in plan_text:
        plan_text = plan_text.split("```json")[1].split("```")[0].strip()
    elif "```" in plan_text:
        plan_text = plan_text.split("```")[1].split("```")[0].strip()
    
    try:
        plan = json.loads(plan_text)
        print(f"[å¤šæ­¥éª¤è§„åˆ’] éœ€è¦åˆ›å»ºæ–‡ä»¶: {plan.get('needs_file_creation', False)}")
        print(f"            å‘½ä»¤æ•°é‡: {len(plan.get('commands', []))}")
        
        return {
            "needs_file_creation": plan.get("needs_file_creation", False),
            "file_path": plan.get("file_path", ""),
            "file_content": plan.get("file_content", ""),
            "commands": plan.get("commands", [])
        }
    except json.JSONDecodeError:
        print(f"[å¤šæ­¥éª¤è§„åˆ’] JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return {
            "needs_file_creation": False,
            "file_path": "",
            "file_content": "",
            "commands": [],
            "error": "æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’"
        }


def file_creator(state: AgentState) -> dict:
    """
    åˆ›å»ºæ–‡ä»¶
    """
    file_path = state["file_path"]
    file_content = state["file_content"]
    
    print(f"[æ–‡ä»¶åˆ›å»º] åˆ›å»ºæ–‡ä»¶: {file_path}")
    
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(file_content)
        print(f"[æ–‡ä»¶åˆ›å»º] æˆåŠŸåˆ›å»ºæ–‡ä»¶: {file_path}")
        return {"error": ""}
    except Exception as e:
        error_msg = f"æ–‡ä»¶åˆ›å»ºå¤±è´¥: {str(e)}"
        print(f"[æ–‡ä»¶åˆ›å»º] {error_msg}")
        return {"error": error_msg}


def multi_command_executor(state: AgentState) -> dict:
    """
    æ‰§è¡Œå¤šä¸ªç»ˆç«¯å‘½ä»¤
    """
    commands = state["commands"]
    outputs = []
    
    print(f"[å¤šå‘½ä»¤æ‰§è¡Œ] å…±{len(commands)}ä¸ªå‘½ä»¤")
    
    for idx, command in enumerate(commands, 1):
        print(f"[å¤šå‘½ä»¤æ‰§è¡Œ] æ‰§è¡Œç¬¬{idx}ä¸ªå‘½ä»¤: {command}")
        result = execute_terminal_command(command)
        
        outputs.append({
            "command": command,
            "success": result["success"],
            "output": result["output"],
            "error": result["error"]
        })
        
        if result["success"]:
            print(f"[å¤šå‘½ä»¤æ‰§è¡Œ] ç¬¬{idx}ä¸ªå‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
        else:
            print(f"[å¤šå‘½ä»¤æ‰§è¡Œ] ç¬¬{idx}ä¸ªå‘½ä»¤æ‰§è¡Œå¤±è´¥: {result['error']}")
            # ç»§ç»­æ‰§è¡Œåç»­å‘½ä»¤ï¼Œä¸ä¸­æ–­
    
    return {"command_outputs": outputs}


def command_executor(state: AgentState) -> dict:
    """
    æ‰§è¡Œç»ˆç«¯å‘½ä»¤
    """
    command = state["command"]

    print(f"[æ‰§è¡Œå‘½ä»¤] {command}")

    result = execute_terminal_command(command)

    if result["success"]:
        print(f"[æ‰§è¡ŒæˆåŠŸ] è¾“å‡ºé•¿åº¦: {len(result['output'])} å­—ç¬¦")
        return {
            "command_output": result["output"],
            "error": ""
        }
    else:
        print(f"[æ‰§è¡Œå¤±è´¥] {result['error']}")
        return {
            "command_output": "",
            "error": result["error"]
        }


def response_formatter(state: AgentState) -> dict:
    """
    æ ¼å¼åŒ–æœ€ç»ˆå“åº”
    """
    if state["intent"] == "terminal_command":
        if state.get("error"):
            response = f"å‘½ä»¤æ‰§è¡Œå¤±è´¥\nå‘½ä»¤: {state['command']}\né”™è¯¯: {state['error']}"
        else:
            response = f"å‘½ä»¤æ‰§è¡ŒæˆåŠŸ\nå‘½ä»¤: {state['command']}\nè¾“å‡º:\n{state['command_output']}"
    elif state["intent"] == "multi_step_command":
        response = "âœ… å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡Œç»“æœ:\n\n"
        
        if state.get("needs_file_creation"):
            response += f"ğŸ“„ åˆ›å»ºæ–‡ä»¶: {state.get('file_path', '')}\n\n"
        
        outputs = state.get("command_outputs", [])
        for idx, output in enumerate(outputs, 1):
            status = "âœ…" if output["success"] else "âŒ"
            response += f"{status} å‘½ä»¤ {idx}: {output['command']}\n"
            if output["success"]:
                response += f"è¾“å‡º:\n{output['output']}\n\n"
            else:
                response += f"é”™è¯¯: {output['error']}\n\n"
    else:
        response = "æŠ±æ­‰,æˆ‘æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚"

    print(f"[æ ¼å¼åŒ–å“åº”] å®Œæˆ")

    return {"response": response}


def question_answerer(state: AgentState) -> dict:
    """
    å›ç­”ç”¨æˆ·é—®é¢˜
    """
    user_input = state["user_input"]

    prompt = f"""ç®€è¦å›ç­”ç”¨æˆ·é—®é¢˜:

{user_input}

å›ç­”:"""

    result = llm.invoke([HumanMessage(content=prompt)])
    response = result.content

    print(f"[é—®é¢˜å›ç­”] ç”Ÿæˆå›ç­”")

    return {"response": response}


# ============================================
# è·¯ç”±å‡½æ•°
# ============================================

def route_by_intent(state: AgentState) -> str:
    """æ ¹æ®æ„å›¾è·¯ç”±åˆ°ä¸åŒå¤„ç†èŠ‚ç‚¹"""
    intent = state["intent"]
    if intent == "terminal_command":
        return "generate_command"
    elif intent == "multi_step_command":
        return "plan_steps"
    elif intent == "question":
        return "answer_question"
    else:
        return "format_response"


def route_after_planning(state: AgentState) -> str:
    """è§„åˆ’åçš„è·¯ç”±: å†³å®šæ˜¯å¦éœ€è¦åˆ›å»ºæ–‡ä»¶"""
    if state.get("needs_file_creation", False):
        return "create_file"
    else:
        return "execute_multi_commands"


# ============================================
# æ„å»ºå·¥ä½œæµ
# ============================================

def build_agent() -> StateGraph:
    """æ„å»ºAIæ™ºèƒ½ä½“å·¥ä½œæµ"""

    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyze_intent", intent_analyzer)
    workflow.add_node("generate_command", command_generator)
    workflow.add_node("execute_command", command_executor)
    workflow.add_node("plan_steps", multi_step_planner)
    workflow.add_node("create_file", file_creator)
    workflow.add_node("execute_multi_commands", multi_command_executor)
    workflow.add_node("format_response", response_formatter)
    workflow.add_node("answer_question", question_answerer)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("analyze_intent")

    # æ¡ä»¶è·¯ç”±: æ ¹æ®æ„å›¾é€‰æ‹©è·¯å¾„
    workflow.add_conditional_edges(
        "analyze_intent",
        route_by_intent,
        {
            "generate_command": "generate_command",
            "plan_steps": "plan_steps",
            "answer_question": "answer_question",
            "format_response": "format_response"
        }
    )

    # å•æ­¥å‘½ä»¤è·¯å¾„
    workflow.add_edge("generate_command", "execute_command")
    workflow.add_edge("execute_command", "format_response")
    
    # å¤šæ­¥éª¤å‘½ä»¤è·¯å¾„
    workflow.add_conditional_edges(
        "plan_steps",
        route_after_planning,
        {
            "create_file": "create_file",
            "execute_multi_commands": "execute_multi_commands"
        }
    )
    workflow.add_edge("create_file", "execute_multi_commands")
    workflow.add_edge("execute_multi_commands", "format_response")
    
    # ç»“æŸè·¯å¾„
    workflow.add_edge("format_response", END)
    workflow.add_edge("answer_question", END)

    return workflow.compile()


# ============================================
# ä¸»å‡½æ•°
# ============================================

def main():
    """è¿è¡ŒAIç»ˆç«¯æ§åˆ¶æ™ºèƒ½ä½“Demo"""

    agent = build_agent()

    test_inputs = [
        "æ˜¾ç¤ºå½“å‰ç›®å½•çš„è·¯å¾„",
        "åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶",
        "æŸ¥çœ‹Pythonç‰ˆæœ¬",
        "ä»€ä¹ˆæ˜¯LangGraph?",
        "åˆ›å»ºä¸€ä¸ªPythonæ–‡ä»¶hello.pyï¼Œå†…å®¹æ˜¯print('Hello World')ï¼Œç„¶åæ‰§è¡Œå®ƒ",
    ]

    print("=" * 80)
    print("AIæ™ºèƒ½ä½“ç»ˆç«¯æ§åˆ¶å·¥å…·Demo")
    print("æ¼”ç¤ºAI Agentå¦‚ä½•ç†è§£è‡ªç„¶è¯­è¨€å¹¶æ‰§è¡Œç»ˆç«¯å‘½ä»¤")
    print("=" * 80)

    for user_input in test_inputs:
        print(f"\n{'=' * 80}")
        print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
        print(f"{'-' * 80}")

        initial_state: AgentState = {
            "user_input": user_input,
            "intent": "unknown",
            "command": "",
            "commands": [],
            "command_output": "",
            "command_outputs": [],
            "response": "",
            "error": "",
            "needs_file_creation": False,
            "file_path": "",
            "file_content": ""
        }

        result = agent.invoke(initial_state)

        print(f"{'-' * 80}")
        print(f"æœ€ç»ˆå“åº”:\n{result['response']}")
        print()


if __name__ == "__main__":
    main()
