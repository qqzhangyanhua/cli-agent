"""
æ„å›¾åˆ†æå’Œè§„åˆ’èŠ‚ç‚¹
åŒ…å«æ„å›¾è¯†åˆ«ã€å‘½ä»¤ç”Ÿæˆã€å¤šæ­¥éª¤è§„åˆ’ã€MCPå·¥å…·è§„åˆ’
"""

import json
import platform
from datetime import datetime
from langchain_core.messages import HumanMessage

from src.core.agent_config import AgentState, LLM_CONFIG, LLM_CONFIG2
from src.core.agent_memory import memory
from src.core.agent_llm import llm, llm_code
from src.mcp.mcp_manager import mcp_manager
from src.core.json_utils import extract_json_str, safe_json_loads


def intent_analyzer(state: AgentState) -> dict:
    """åˆ†æç”¨æˆ·æ„å›¾ï¼ˆå¸¦ä¸Šä¸‹æ–‡å’Œæ–‡ä»¶å¼•ç”¨ï¼‰"""
    user_input = state["user_input"]
    context = memory.get_context_string()

    # å…ˆè¿›è¡ŒåŸºäºè§„åˆ™çš„å¿«é€Ÿåˆ¤æ–­ï¼ˆæé«˜å‡†ç¡®ç‡ï¼‰
    user_input_lower = user_input.lower()

    # æŸ¥è¯¢å¾…åŠçš„å…³é”®è¯
    query_keywords = [
        "æœ‰ä»€ä¹ˆ",
        "è¦åšä»€ä¹ˆ",
        "åšä»€ä¹ˆ",
        "å¾…åŠ",
        "ä»»åŠ¡",
        "å®‰æ’",
        "æŸ¥çœ‹",
        "çœ‹çœ‹",
        "æœ‰å“ªäº›",
        "ä»€ä¹ˆäº‹",
        "æ—¥ç¨‹",
    ]

    # æ—¶é—´ç›¸å…³è¯æ±‡ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æ¶‰åŠæ—¶é—´ï¼‰
    time_keywords = [
        "ä»Šå¤©",
        "æ˜å¤©",
        "åå¤©",
        "å‘¨ä¸€",
        "å‘¨äºŒ",
        "å‘¨ä¸‰",
        "å‘¨å››",
        "å‘¨äº”",
        "å‘¨å…­",
        "å‘¨æ—¥",
        "ä¸‹å‘¨",
        "ç‚¹",
        "æ—¶",
        "ä¸Šåˆ",
        "ä¸‹åˆ",
        "æ—©ä¸Š",
        "æ™šä¸Š",
        "ä¸­åˆ",
    ]

    # è§„åˆ™1: å¦‚æœåŒ…å«æŸ¥è¯¢å…³é”®è¯ + æ—¶é—´è¯ï¼Œå¾ˆå¯èƒ½æ˜¯æŸ¥è¯¢å¾…åŠ
    has_query_keyword = any(kw in user_input_lower for kw in query_keywords)
    has_time_word = any(kw in user_input_lower for kw in time_keywords)

    if has_query_keyword and has_time_word:
        print(f"\n[æ„å›¾åˆ†æ] {user_input[:50]}...")
        print(f"           è§„åˆ™åŒ¹é…: query_todo")
        print(f"           æ„å›¾: query_todo")
        return {"intent": "query_todo"}

    # è§„åˆ™2: å¦‚æœåŒ…å«æ—¶é—´è¯ä½†æ²¡æœ‰ç–‘é—®è¯ï¼Œä¸”ä¸æ˜¯ç–‘é—®å¥ï¼Œå¾ˆå¯èƒ½æ˜¯æ·»åŠ å¾…åŠ
    # ä¾‹å¦‚ï¼š\"æ˜å¤©å¼€ä¼š\"ã€\"ä»Šå¤©18ç‚¹ç»™é™ˆé¾™æ‰“ç”µè¯\"
    if has_time_word and not has_query_keyword:
        # æ’é™¤ç–‘é—®å¥ï¼ˆä»¥é—®å·ç»“å°¾ï¼‰
        if not user_input.strip().endswith("ï¼Ÿ") and not user_input.strip().endswith(
            "?"
        ):
            print(f"\n[æ„å›¾åˆ†æ] {user_input[:50]}...")
            print(f"           è§„åˆ™åŒ¹é…: add_todo")
            print(f"           æ„å›¾: add_todo")
            return {"intent": "add_todo"}

    # å¦‚æœè§„åˆ™æ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨ LLM åˆ†æ
    # æ„å»ºæ–‡ä»¶å¼•ç”¨ä¸Šä¸‹æ–‡
    file_context = ""
    if state.get("referenced_files"):
        file_context = "\n\nğŸ“ ç”¨æˆ·å¼•ç”¨çš„æ–‡ä»¶:\n"
        for ref in state["referenced_files"]:
            file_context += f"- {ref['path']} (æ¥è‡ª {ref['original_ref']})\n"

        # æ·»åŠ æ–‡ä»¶å†…å®¹æ‘˜è¦
        if state.get("file_contents"):
            file_context += "\nğŸ“„ æ–‡ä»¶å†…å®¹å·²åŠ è½½ï¼Œå¯ä»¥ç›´æ¥åˆ†æå’Œæ“ä½œè¿™äº›æ–‡ä»¶ã€‚\n"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç»ˆç«¯åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå¯¹è¯å†å²ï¼Œåˆ†æç”¨æˆ·æ„å›¾ã€‚

{context}{file_context}

å½“å‰ç”¨æˆ·è¾“å…¥: {user_input}

åˆ¤æ–­è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä»ä¸Šåˆ°ä¸‹åŒ¹é…ï¼‰:

1. æ·»åŠ å¾…åŠäº‹é¡¹ (add_todo) - ç”¨æˆ·æƒ³è®°å½•ã€æ·»åŠ ã€è®¾ç½®ä¸€ä¸ªå¾…åŠæˆ–æé†’
   å…³é”®ç‰¹å¾ï¼šåŒ…å«æ—¶é—´ç‚¹ + è¦åšçš„äº‹æƒ…
   ç¤ºä¾‹ï¼š
   - \"ä»Šå¤©18ç‚¹ç»™é™ˆé¾™æ‰“ç”µè¯\"
   - \"æ˜å¤©ä¸Šåˆ10ç‚¹å¼€ä¼š\"
   - \"å‘¨äº”ä¸‹åˆ3ç‚¹äº¤æŠ¥å‘Š\"
   - \"æé†’æˆ‘æ˜å¤©ä¹°èœ\"
   - \"è®°å½•ï¼šåå¤©è§å®¢æˆ·\"

2. æŸ¥è¯¢å¾…åŠäº‹é¡¹ (query_todo) - ç”¨æˆ·æƒ³æŸ¥çœ‹ã€è¯¢é—®å¾…åŠäº‹é¡¹
   å…³é”®ç‰¹å¾ï¼šè¯¢é—®\"æœ‰ä»€ä¹ˆ\"ã€\"è¦åšä»€ä¹ˆ\"ã€\"å¾…åŠ\"ã€\"ä»»åŠ¡\"ã€\"å®‰æ’\"
   ç¤ºä¾‹ï¼š
   - \"ä»Šå¤©æœ‰ä»€ä¹ˆè¦åšçš„\"
   - \"æ˜å¤©çš„å¾…åŠ\"
   - \"è¿™å‘¨æœ‰ä»€ä¹ˆä»»åŠ¡\"
   - \"æˆ‘ä»Šå¤©è¦åšä»€ä¹ˆ\"
   - \"æŸ¥çœ‹æˆ‘çš„å¾…åŠ\"

3. Git commit (git_commit) - ç”ŸæˆGit commitæ¶ˆæ¯

4. MCPå·¥å…· (mcp_tool_call) - æ–‡ä»¶æ“ä½œã€æˆªå›¾ã€å‰ªè´´æ¿ç­‰

5. ç»ˆç«¯å‘½ä»¤ (terminal_command) - æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
   å…³é”®ç‰¹å¾ï¼šåŒ…å«\"æ‰“å¼€\"ã€\"ç›®å½•\"ã€\"æ–‡ä»¶å¤¹\"ã€\"ç»ˆç«¯\"ç­‰æ“ä½œè¯æ±‡
   ç¤ºä¾‹ï¼š
   - \"æ‰“å¼€å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•\"
   - \"åœ¨æ–°çš„ç»ˆç«¯æ‰“å¼€å½“å‰ç›®å½•\"
   - \"æ‰“å¼€è¿™ä¸ªæ–‡ä»¶å¤¹\"
   - \"ç”¨æ–‡ä»¶ç®¡ç†å™¨æ‰“å¼€\"
   - \"åœ¨Finderä¸­æ‰“å¼€\"
   - \"åœ¨èµ„æºç®¡ç†å™¨ä¸­æ‰“å¼€\"

6. å¤šæ­¥éª¤å‘½ä»¤ (multi_step_command) - éœ€è¦å¤šæ­¥éª¤çš„ä»»åŠ¡

7. é—®é¢˜ (question) - å…¶ä»–é—®ç­”ã€è§£é‡Šã€å»ºè®®ç­‰

**é‡è¦**ï¼š
- å¦‚æœè¾“å…¥åŒ…å«\"ä»Šå¤©/æ˜å¤©/å‘¨X + æ—¶é—´ + åŠ¨ä½œ\"çš„æ¨¡å¼ï¼Œä¼˜å…ˆåˆ¤æ–­ä¸º add_todo
- å¦‚æœè¾“å…¥è¯¢é—®\"æœ‰ä»€ä¹ˆè¦åš/å¾…åŠ/ä»»åŠ¡/å®‰æ’\"ï¼Œä¼˜å…ˆåˆ¤æ–­ä¸º query_todo
- å¦‚æœè¾“å…¥åŒ…å«\"æ‰“å¼€\"+\"ç›®å½•/æ–‡ä»¶å¤¹/ç»ˆç«¯\"ç­‰è¯æ±‡ï¼Œä¼˜å…ˆåˆ¤æ–­ä¸º terminal_command
- åªæœ‰åœ¨æ˜ç¡®ä¸å±äºå¾…åŠç›¸å…³æ—¶ï¼Œæ‰åˆ¤æ–­ä¸º question

åªè¿”å›ä¸€ä¸ªè¯: 'add_todo', 'query_todo', 'git_commit', 'mcp_tool_call', 'terminal_command', 'multi_step_command' æˆ– 'question'

æ„å›¾:"""

    result = llm.invoke([HumanMessage(content=prompt)])
    intent = result.content.strip().lower()

    if intent not in [
        "add_todo",
        "query_todo",
        "git_commit",
        "mcp_tool_call",
        "terminal_command",
        "multi_step_command",
        "question",
    ]:
        intent = "question"

    print(f"\n[æ„å›¾åˆ†æ] {user_input[:50]}...")
    print(f"           ä½¿ç”¨æ¨¡å‹: {LLM_CONFIG['model']}")
    print(f"           æ„å›¾: {intent}")

    return {"intent": intent}


def command_generator(state: AgentState) -> dict:
    """ç”Ÿæˆç»ˆç«¯å‘½ä»¤"""
    user_input = state["user_input"]
    recent_commands = memory.get_recent_commands()

    # æ£€æµ‹æ“ä½œç³»ç»Ÿ
    os_type = platform.system()

    # æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®ç¤ºä¾‹
    if os_type == "Windows":
        examples = """ç¤ºä¾‹(Windows):
- \"åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶\" -> dir æˆ– Get-ChildItem
- \"æŸ¥çœ‹Pythonç‰ˆæœ¬\" -> python --version
- \"æ˜¾ç¤ºå½“å‰è·¯å¾„\" -> cd
- \"æŸ¥çœ‹æ–‡ä»¶å†…å®¹\" -> type filename.txt æˆ– Get-Content filename.txt
- \"åˆ›å»ºç›®å½•\" -> mkdir dirname
- \"åˆ é™¤æ–‡ä»¶\" -> del filename
- \"å¤åˆ¶æ–‡ä»¶\" -> copy source dest
- \"ç§»åŠ¨æ–‡ä»¶\" -> move source dest
- \"æ‰“å¼€å½“å‰ç›®å½•\" -> explorer .
- \"æ‰“å¼€æ–‡ä»¶å¤¹\" -> explorer .
- \"æ‰“å¼€å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•\" -> explorer .
- \"æ‰“å¼€ç»ˆç«¯\" -> start cmd /k \"cd /d %cd%\"
- \"åœ¨æ–°çš„ç»ˆç«¯æ‰“å¼€å½“å‰ç›®å½•\" -> start cmd /k \"cd /d %cd%\"
- \"ç”¨æ–‡ä»¶ç®¡ç†å™¨æ‰“å¼€\" -> explorer ."""
    else:
        examples = """ç¤ºä¾‹(Unix/Linux/macOS):
- \"åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶\" -> ls -la
- \"æŸ¥çœ‹Pythonç‰ˆæœ¬\" -> python3 --version
- \"æ˜¾ç¤ºå½“å‰è·¯å¾„\" -> pwd
- \"æŸ¥çœ‹æ–‡ä»¶å†…å®¹\" -> cat filename.txt
- \"åˆ›å»ºç›®å½•\" -> mkdir dirname
- \"åˆ é™¤æ–‡ä»¶\" -> rm filename
- \"å¤åˆ¶æ–‡ä»¶\" -> cp source dest
- \"ç§»åŠ¨æ–‡ä»¶\" -> mv source dest
- \"æ‰“å¼€å½“å‰ç›®å½•\" -> open .
- \"æ‰“å¼€æ–‡ä»¶å¤¹\" -> open .
- \"æ‰“å¼€å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•\" -> open .
- \"æ‰“å¼€ç»ˆç«¯\" -> open -a Terminal .
- \"åœ¨æ–°çš„ç»ˆç«¯æ‰“å¼€å½“å‰ç›®å½•\" -> open -a Terminal .
- \"ç”¨æ–‡ä»¶ç®¡ç†å™¨æ‰“å¼€\" -> open ."""

    prompt = f"""å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¯·æ±‚è½¬æ¢ä¸ºç»ˆç«¯å‘½ä»¤.

æ“ä½œç³»ç»Ÿ: {os_type}
{recent_commands}

å½“å‰è¯·æ±‚: {user_input}

{examples}

**é‡è¦è¯­ä¹‰åŒºåˆ†**:
- \"æ‰“å¼€å½“å‰ç›®å½•\" -> æ‰“å¼€å·¥ä½œç›®å½•æœ¬èº« (ä½¿ç”¨ . )
- \"æ‰“å¼€æ–‡ä»¶å¤¹\" -> æ‰“å¼€å·¥ä½œç›®å½•æœ¬èº« (ä½¿ç”¨ . )
- \"æ‰“å¼€å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•\" -> æ‰“å¼€å·¥ä½œç›®å½•æœ¬èº« (ä½¿ç”¨ . )
- \"æ‰“å¼€ç»ˆç«¯\" -> åœ¨å½“å‰å·¥ä½œç›®å½•æ‰“å¼€æ–°ç»ˆç«¯ (macOS: open -a Terminal ., Windows: start cmd /k \"cd /d %cd%\")

**é‡è¦**:
- å¿…é¡»ç”Ÿæˆé€‚åˆ {os_type} ç³»ç»Ÿçš„å‘½ä»¤
- åªè¿”å›å‘½ä»¤æœ¬èº«, ä¸è¦è§£é‡Š
- ä¸è¦æ·»åŠ æ³¨é‡Šæˆ–è¯´æ˜
- æ³¨æ„åŒºåˆ†æ‰“å¼€å½“å‰ç›®å½•(.)å’Œçˆ¶ç›®å½•(..)çš„è¯­ä¹‰

å‘½ä»¤:"""

    result = llm_code.invoke([HumanMessage(content=prompt)])
    command = result.content.strip()

    print(f"[å‘½ä»¤ç”Ÿæˆ] {command}")
    print(f"           ä½¿ç”¨æ¨¡å‹: {LLM_CONFIG2['model']}")
    print(f"           æ“ä½œç³»ç»Ÿ: {os_type}")

    return {"command": command}


def multi_step_planner(state: AgentState) -> dict:
    """å¤šæ­¥éª¤è§„åˆ’"""
    user_input = state["user_input"]
    recent_commands = memory.get_recent_commands()

    # æ£€æµ‹æ“ä½œç³»ç»Ÿ
    os_type = platform.system()

    prompt = f"""åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œè¿”å›JSONæ ¼å¼çš„æ‰§è¡Œè®¡åˆ’ã€‚

æ“ä½œç³»ç»Ÿ: {os_type}
{recent_commands}

ç”¨æˆ·è¯·æ±‚: {user_input}

è¿”å›JSONå¯¹è±¡:
{{
  "needs_file_creation": true/false,
  "file_path": "æ–‡ä»¶è·¯å¾„",
  "file_content": "æ–‡ä»¶å†…å®¹",
  "commands": ["å‘½ä»¤1", "å‘½ä»¤2"]
}}

**é‡è¦**: ç”Ÿæˆçš„å‘½ä»¤å¿…é¡»é€‚åˆ {os_type} ç³»ç»Ÿ

åªè¿”å›JSON:"""

    result = llm_code.invoke([HumanMessage(content=prompt)])
    plan_text = extract_json_str(result.content.strip())

    obj, err = safe_json_loads(plan_text)
    if err:
        print(f"[å¤šæ­¥éª¤è§„åˆ’] JSONè§£æå¤±è´¥: {err}")
        return {
            "needs_file_creation": False,
            "file_path": "",
            "file_content": "",
            "commands": [],
            "error": "æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’",
        }
    try:
        plan = obj
        print(f"[å¤šæ­¥éª¤è§„åˆ’] ä½¿ç”¨æ¨¡å‹: {LLM_CONFIG2['model']}")
        print(f"            æ“ä½œç³»ç»Ÿ: {os_type}")
        print(f"            éœ€è¦åˆ›å»ºæ–‡ä»¶: {plan.get('needs_file_creation', False)}")
        print(f"            å‘½ä»¤æ•°é‡: {len(plan.get('commands', []))}")

        return {
            "needs_file_creation": plan.get("needs_file_creation", False),
            "file_path": plan.get("file_path", ""),
            "file_content": plan.get("file_content", ""),
            "commands": plan.get("commands", []),
        }
    except json.JSONDecodeError:
        print(f"[å¤šæ­¥éª¤è§„åˆ’] JSONè§£æå¤±è´¥")
        return {
            "needs_file_creation": False,
            "file_path": "",
            "file_content": "",
            "commands": [],
            "error": "æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’",
        }


def mcp_tool_planner(state: AgentState) -> dict:
    """è§„åˆ’MCPå·¥å…·è°ƒç”¨"""
    user_input = state["user_input"]

    available_tools = mcp_manager.list_available_tools()
    tools_desc = "\n".join(
        [
            f"- {t['name']}: {t['description']} (å‚æ•°: {', '.join(t['params'])})"
            for t in available_tools
        ]
    )

    prompt = f"""åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„MCPå·¥å…·å¹¶è¿”å›JSONæ ¼å¼ã€‚

å¯ç”¨å·¥å…·:
{tools_desc}

ç”¨æˆ·è¯·æ±‚: {user_input}

è¿”å›JSONæ ¼å¼:
{{
  "tool": "å·¥å…·åç§°",
  "params": {{å‚æ•°å: å‚æ•°å€¼}}
}}

ç¤ºä¾‹:
è¾“å…¥: \"è¯»å–README.mdæ–‡ä»¶\"
è¾“å‡º: {{
  "tool": "fs_read",
  "params": {{"file_path": "README.md"}}
}}

åªè¿”å›JSON:"""

    result = llm_code.invoke([HumanMessage(content=prompt)])
    plan_text = extract_json_str(result.content.strip())
    obj, err = safe_json_loads(plan_text)
    if err:
        print(f"[MCPå·¥å…·è§„åˆ’] JSONè§£æå¤±è´¥: {err}")
        return {"mcp_tool": "", "mcp_params": {}, "error": "æ— æ³•è§£æMCPå·¥å…·è§„åˆ’"}
    try:
        plan = obj
        print(f"[MCPå·¥å…·è§„åˆ’] ä½¿ç”¨æ¨¡å‹: {LLM_CONFIG2['model']}")
        print(f"            å·¥å…·: {plan.get('tool', 'unknown')}")
        print(f"            å‚æ•°: {plan.get('params', {})}")

        return {"mcp_tool": plan.get("tool", ""), "mcp_params": plan.get("params", {})}
    except Exception as e:
        print(f"[MCPå·¥å…·è§„åˆ’] è§£æå¤±è´¥: {e}")
        return {"mcp_tool": "", "mcp_params": {}, "error": "æ— æ³•è§£æMCPå·¥å…·è§„åˆ’"}
